{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2])\n",
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "import torch as t\n",
    "from torch import nn\n",
    "embedding = t.nn.Embedding(10,2) # 十个词，每个词用2维词向量表示\n",
    "input = t.arange(0,6).view(3,2).long() # 三个句子，每句有两个词\n",
    "input = t.autograd.Variable(input)\n",
    "output = embedding(input)\n",
    "print output.size()\n",
    "print embedding.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n",
      "torch.Size([2, 3, 20])\n",
      "torch.Size([2, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "#输入词用10维词向量表示\n",
    "#隐藏元用20维词向量表示\n",
    "#两层的lstm\n",
    "rnn = nn.LSTM(10,20,2)\n",
    "#输入每句话有五个词，每个词由十维的词向量表示，总共有三句话（batchsize）\n",
    "input =Variable(t.randn(5,3,10))\n",
    "#隐藏元hidden_state 和cell_state的初始值\n",
    "#形状 num_layers，batch_size, hidden_size\n",
    "h0 = Variable(t.zeros(2,3,20))\n",
    "c0 = Variable(t.zeros(2,3,20))\n",
    "#output是最后一层所有隐藏元的值\n",
    "#hn和cn是所有层的最后一个隐藏元的值\n",
    "output, (hn, cn) = rnn(input, (h0,c0))\n",
    "\n",
    "print output.size()\n",
    "print (hn.size())\n",
    "print cn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#对文字的预处理分为以下几步：\n",
    "#中文分词\n",
    "#将词用序号表示（word2idx），并过滤低频词\n",
    "#将所有描述补齐到等长（pad_sequence）\n",
    "#利用pack_padded_sequence进行计算加速\n",
    "from torch.nn.utils.rnn import pack_padded_sequence,pad_packed_sequence\n",
    "#dummydata\n",
    "sen1 = [1,1,1]\n",
    "sen2=[2,2,2,2]\n",
    "sen3=[3,3,3,3,3,3,3,3,3,3,3,3]\n",
    "sen4=[4,4,4,4,4]\n",
    "sentences = [sen1,sen2,sen3,sen4]\n",
    "sentences = sorted(sentences,key = lambda x:len(x),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 4, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths= [5 if len(sen) > 5 else len(sen) for sen in sentences]\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_sen(sen,length=5,padded_num=0):\n",
    "    origin_len = len(sen)\n",
    "    padded_sen = sen[:length]\n",
    "    padded_sen = padded_sen + [padded_num for _ in range(origin_len,length)]\n",
    "    return padded_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 3, 3, 3, 3], [4, 4, 4, 4, 4], [2, 2, 2, 2, 0], [1, 1, 1, 0, 0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sentences = [pad_sen(sen) for sen in sentences]\n",
    "pad_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3  4  2  1\n",
       " 3  4  2  1\n",
       " 3  4  2  1\n",
       " 3  4  2  0\n",
       " 3  4  0  0\n",
       "[torch.LongTensor of size 5x4]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4*5 batch_size = 4  词=5\n",
    "pad_tensor = t.Tensor(pad_sentences).long()\n",
    "\n",
    "#5*4\n",
    "pad_tensor = pad_tensor.t()\n",
    "pad_variable = t.autograd.Variable(pad_tensor)\n",
    "pad_variable #一列是一句话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  2.5003  0.4281\n",
       " -0.5557  2.0929\n",
       " -0.2063  1.1136\n",
       "  0.3661 -0.9053\n",
       "\n",
       "(1 ,.,.) = \n",
       "  2.5003  0.4281\n",
       " -0.5557  2.0929\n",
       " -0.2063  1.1136\n",
       "  0.3661 -0.9053\n",
       "\n",
       "(2 ,.,.) = \n",
       "  2.5003  0.4281\n",
       " -0.5557  2.0929\n",
       " -0.2063  1.1136\n",
       "  0.3661 -0.9053\n",
       "\n",
       "(3 ,.,.) = \n",
       "  2.5003  0.4281\n",
       " -0.5557  2.0929\n",
       " -0.2063  1.1136\n",
       " -1.3850 -0.7451\n",
       "\n",
       "(4 ,.,.) = \n",
       "  2.5003  0.4281\n",
       " -0.5557  2.0929\n",
       " -1.3850 -0.7451\n",
       " -1.3850 -0.7451\n",
       "[torch.FloatTensor of size 5x4x2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(5,2) #五个词 每个词2维\n",
    "pad_embeddings = embedding(pad_variable)\n",
    "pad_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       " 2.5003  0.4281\n",
       "-0.5557  2.0929\n",
       "-0.2063  1.1136\n",
       " 0.3661 -0.9053\n",
       " 2.5003  0.4281\n",
       "-0.5557  2.0929\n",
       "-0.2063  1.1136\n",
       " 0.3661 -0.9053\n",
       " 2.5003  0.4281\n",
       "-0.5557  2.0929\n",
       "-0.2063  1.1136\n",
       " 0.3661 -0.9053\n",
       " 2.5003  0.4281\n",
       "-0.5557  2.0929\n",
       "-0.2063  1.1136\n",
       " 2.5003  0.4281\n",
       "-0.5557  2.0929\n",
       "[torch.FloatTensor of size 17x2]\n",
       ", batch_sizes=[4, 4, 4, 3, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pack数据\n",
    "packed_variable = pack_padded_sequence(pad_embeddings,lengths)\n",
    "packed_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,.,.) = \n",
       "   0.1774  0.5673  0.2668\n",
       "  -0.0178 -0.0922  0.0357\n",
       "   0.0001  0.0365  0.0390\n",
       "   0.1024  0.2378  0.0083\n",
       " \n",
       " (1 ,.,.) = \n",
       "   0.2635  0.7143  0.4647\n",
       "  -0.0245 -0.1127  0.0401\n",
       "  -0.0043  0.0572  0.0532\n",
       "   0.1229  0.3438  0.0320\n",
       " \n",
       " (2 ,.,.) = \n",
       "   0.2939  0.7590  0.5632\n",
       "  -0.0272 -0.1185  0.0404\n",
       "  -0.0081  0.0665  0.0583\n",
       "   0.1192  0.3930  0.0538\n",
       " \n",
       " (3 ,.,.) = \n",
       "   0.3050  0.7753  0.6091\n",
       "  -0.0282 -0.1204  0.0402\n",
       "  -0.0105  0.0701  0.0601\n",
       "   0.0000  0.0000  0.0000\n",
       " \n",
       " (4 ,.,.) = \n",
       "   0.3091  0.7818  0.6318\n",
       "  -0.0286 -0.1211  0.0402\n",
       "   0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000\n",
       " [torch.FloatTensor of size 5x4x3], [5, 5, 4, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = t.nn.LSTM(2,3) #2词向量，3隐藏元\n",
    "output, hn = rnn(packed_variable)\n",
    "output = pad_packed_sequence(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图像数据处理，修改最后一层\n",
    "#第一种做法  修改forword函数\n",
    "from torchvision.models import resnet50\n",
    "def new_forward (self, x):\n",
    "    x = self.conv1(x)\n",
    "    #省略中间\n",
    "    x = self.avgpool(x)\n",
    "    x = x.vioew(x.size(0), -1)\n",
    "    #x = self.fc(x)\n",
    "    return x\n",
    "model = resnet50(pretrained=True)\n",
    "#覆盖\n",
    "model.forward = lambda x:new_forward(model,x)\n",
    "#或者 model.__class__.forward = new_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第二种做法  删除全连接层 改成恒等映射\n",
    "model = resnet50(pretrained = True)\n",
    "del model.fc\n",
    "model.fc = lambda x:x\n",
    "model.cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
